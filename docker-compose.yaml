version: "3.9"
x-clickhouse-credentials: &clickhouse-credentials
  CLICKHOUSE_USER: dittofeed
  CLICKHOUSE_PASSWORD: password
x-backend-app-env: &backend-app-env
  <<: *clickhouse-credentials
  NODE_ENV: development
  DATABASE_URL: "postgresql://postgres:password@postgres:5432/dittofeed?connect_timeout=60"
  KAFKA_BROKERS: "kafka:29092"
  KAFKA_USERNAME: "admin"
  KAFKA_PASSWORD: "password"
  KAFKA_ENABLE_ADMIN_SASL: "false"
  CLICKHOUSE_HOST: "http://clickhouse-server:8123"
  TEMPORAL_ADDRESS: "temporal:7233"
  API_HOST: "0.0.0.0"
  LOG_CONFIG: true
services:
  dashboard:
    build:
      context: .
      dockerfile: ./packages/dashboard/Dockerfile
    profiles: ["apps", "apps-api", "apps-worker"]
    volumes:
      - ./mnt:/dittofeed-mnt
    ports:
      - "3000:3000"
    depends_on:
      - postgres
      - temporal
      - api
      - clickhouse-server
    environment:
      <<: *backend-app-env
    networks:
      - dittofeed-network
  api:
    build:
      context: .
      dockerfile: ./packages/api/Dockerfile
    profiles: ["apps", "apps-dashboard", "apps-worker"]
    volumes:
      - ./mnt:/dittofeed-mnt
    ports:
      - "3001:3001"
    depends_on:
      - postgres
      - clickhouse-server
      - temporal
    environment:
      <<: *backend-app-env
      BOOTSTRAP_EVENTS: true
    networks:
      - dittofeed-network
  worker:
    build:
      context: .
      dockerfile: ./packages/worker/Dockerfile
    profiles: ["apps", "apps-dashboard", "apps-api"]
    volumes:
      - ./mnt:/dittofeed-mnt
    depends_on:
      - postgres
      - temporal
      - clickhouse-server
    environment:
      <<: *backend-app-env
    networks:
      - dittofeed-network
  lite:
    build:
      context: .
      dockerfile: ./packages/lite/Dockerfile
    profiles: ["apps-lite"]
    volumes:
      - ./mnt:/dittofeed-mnt
    ports:
      - "3000:3000"
    depends_on:
      - postgres
      - temporal
      - clickhouse-server
    environment:
      <<: *backend-app-env
      DASHBOARD_URL: "http://localhost:3000"
      DASHBOARD_API_BASE: "http://localhost:3000"
    networks:
      - dittofeed-network
  admin-cli:
    build:
      context: .
      dockerfile: ./packages/admin-cli/Dockerfile
    entrypoint: null
    profiles: ["apps", "admin-cli"]
    command: tail -f /dev/null
    tty: true
    depends_on:
      - postgres
      - temporal
      - clickhouse-server
    environment:
      <<: *backend-app-env
    volumes:
      - ./packages/admin-cli/src:/service/packages/admin-cli/src
      - ./packages/api/src:/service/packages/api/src
      - ./packages/backend-lib/src:/service/packages/backend-lib/src
      - ./packages/dashboard/src:/service/packages/dashboard/src
      - ./packages/emailo/src:/service/packages/emailo/src
      - ./packages/isomorphic-lib/src:/service/packages/isomorphic-lib/src
      - ./packages/lite/src:/service/packages/lite/src
      - ./packages/worker/src:/service/packages/worker/src
    networks:
      - dittofeed-network
  temporal:
    container_name: temporal
    depends_on:
      - postgres
    environment:
      - DB=postgresql
      - DB_PORT=5432
      - POSTGRES_USER=postgres
      - POSTGRES_PWD=password
      - POSTGRES_SEEDS=postgres
      - DYNAMIC_CONFIG_FILE_PATH=config/dynamicconfig/dev.yaml
    image: temporalio/auto-setup:1.18.5
    labels:
      kompose.volume.type: configMap
    networks:
      - dittofeed-network
    ports:
      - 7433:7233
    volumes:
      - ./packages/backend-lib/temporal-dynamicconfig:/etc/temporal/config/dynamicconfig
      - 
        type: bind
        source: dev.yaml
        target: /etc/temporal/config/dynamicconfig/dev.yaml
        content: |
          limit.maxIDLength:
            - value: 255
              constraints: {}
          system.forceSearchAttributesCacheRefreshOnRead:
            - value: true
              constraints: {}
      
  temporal-ui:
    profiles: ["temporal-ui"]
    container_name: temporal-ui
    restart: always
    logging:
      driver: "local"
    depends_on:
      - temporal
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CORS_ORIGINS=http://localhost:3000
    image: temporalio/ui:${TEMPORAL_UI_VERSION:-2.22.1}
    networks:
      - dittofeed-network
    ports:
      - 8080:8080
  postgres:
    image: "postgres:15"
    restart: always
    environment:
      POSTGRES_PASSWORD: password
      POSTGRES_DB: dittofeed
      POSTGRES_USER: postgres
    ports:
      - "5452:5432"
    volumes:
      - postgres:/var/lib/postgresql/data
    networks:
      - dittofeed-network
  kafka:
    image: redpandadata/redpanda:v23.1.1
    profiles: ["kafka"]
    ports:
      - 9092:9092
      - 18081:18081
      - 18082:18082
      - 19644:9644
    entrypoint:
      - /bin/sh
      - -c
      - |
        set -ex
        /usr/local/bin/supervisord -d
        
        # Create Redpanda configuration with SASL
        cat > /etc/redpanda/redpanda.yaml <<EOF
        redpanda:
          data_directory: /var/lib/redpanda/data
          node_id: 0
          seed_servers: []
          rpc_server:
            address: 0.0.0.0
            port: 33145
          advertised_rpc_api:
            address: kafka
            port: 33145
          kafka_api:
            - address: 0.0.0.0
              port: 29092
              name: internal
            - address: 0.0.0.0
              port: 9092
              name: external
              authentication_method: sasl
          advertised_kafka_api:
            - address: kafka
              port: 29092
              name: internal
            - address: localhost
              port: 9092
              name: external
          admin:
            - address: 0.0.0.0
              port: 9644
          superusers:
            - admin
        
        pandaproxy:
          pandaproxy_api:
            - address: 0.0.0.0
              port: 8082
              name: internal
            - address: 0.0.0.0
              port: 18082
              name: external
          advertised_pandaproxy_api:
            - address: kafka
              port: 8082
              name: internal
            - address: localhost
              port: 18082
              name: external
        
        schema_registry:
          schema_registry_api:
            - address: 0.0.0.0
              port: 8081
              name: internal
            - address: 0.0.0.0
              port: 18081
              name: external
        
        rpk:
          kafka_api:
            brokers:
              - kafka:29092
              - localhost:9092
          admin_api:
            addresses:
              - kafka:9644
              - localhost:19644
        EOF
        
        # Start Redpanda
        exec /usr/bin/rpk redpanda start \
          --advertise-kafka-addr internal://kafka:29092,external://localhost:9092 \
          --advertise-pandaproxy-addr internal://kafka:8082,external://localhost:18082 \
          --advertise-rpc-addr kafka:33145 \
          --smp 1 \
          --memory 1G \
          --mode dev-container \
          --default-log-level=debug
    volumes:
      - kafka:/var/lib/redpanda/data
    networks:
      - dittofeed-network
  
  kafka-setup:
    image: redpandadata/redpanda:v23.1.1
    profiles: ["kafka"]
    depends_on:
      - kafka
    entrypoint:
      - /bin/sh
      - -c
      - |
        set -ex
        # Wait for Redpanda to be ready
        timeout 60 bash -c 'until rpk cluster info --brokers kafka:29092; do sleep 1; done'
        
        # Create admin user
        rpk acl user create admin --password password --mechanism SCRAM-SHA-256 --brokers kafka:29092 --api-urls http://kafka:9644
        
        # Set superusers (this enables authorization)
        rpk cluster config set superusers '["admin"]' --brokers kafka:29092 --api-urls http://kafka:9644
    networks:
      - dittofeed-network
  clickhouse-server:
    image: clickhouse/clickhouse-server:24.12.6.70-alpine
    ports:
      - "8183:8123"
      - "9000:9000"
      - "9009:9009"
    environment:
      <<: *clickhouse-credentials
    volumes:
      #- ./packages/backend-lib/clickhouse_config.dev.xml:/etc/clickhouse-server/config.xml
      - clickhouse_lib:/var/lib/clickhouse
      - clickhouse_log:/var/log/clickhouse-server
      - 
        type: bind
        source: config.xml
        target: /etc/clickhouse-server/config.xml
        content:  |
          <yandex>
              <logger>
                  <console>true</console>
                  <log remove="remove"/>
                  <errorlog remove="remove"/>
              </logger>
              <http_port>8123</http_port>
              <tcp_port>9000</tcp_port>
              <mysql_port>9004</mysql_port>
              <interserver_http_port>9009</interserver_http_port>
              <max_connections>4096</max_connections>
              <keep_alive_timeout>3</keep_alive_timeout>
              <grpc>
                  <enable_ssl>false</enable_ssl>
                  <ssl_cert_file>/path/to/ssl_cert_file</ssl_cert_file>
                  <ssl_key_file>/path/to/ssl_key_file</ssl_key_file>
                  <ssl_require_client_auth>false</ssl_require_client_auth>
                  <ssl_ca_cert_file>/path/to/ssl_ca_cert_file</ssl_ca_cert_file>
                  <compression>deflate</compression>
                  <compression_level>medium</compression_level>
                  <max_send_message_size>-1</max_send_message_size>
                  <max_receive_message_size>-1</max_receive_message_size>
                  <verbose_logs>false</verbose_logs>
              </grpc>
              <openSSL>
                  <server>
                      <certificateFile>/etc/clickhouse-server/server.crt</certificateFile>
                      <privateKeyFile>/etc/clickhouse-server/server.key</privateKeyFile>
                      <dhParamsFile>/etc/clickhouse-server/dhparam.pem</dhParamsFile>
                      <verificationMode>none</verificationMode>
                      <loadDefaultCAFile>true</loadDefaultCAFile>
                      <cacheSessions>true</cacheSessions>
                      <disableProtocols>sslv2,sslv3</disableProtocols>
                      <preferServerCiphers>true</preferServerCiphers>
                  </server>
                  <client>
                      <loadDefaultCAFile>true</loadDefaultCAFile>
                      <cacheSessions>true</cacheSessions>
                      <disableProtocols>sslv2,sslv3</disableProtocols>
                      <preferServerCiphers>true</preferServerCiphers>
                      <invalidCertificateHandler>
                          <name>RejectCertificateHandler</name>
                      </invalidCertificateHandler>
                  </client>
              </openSSL>
              <max_concurrent_queries>100</max_concurrent_queries>
              <max_server_memory_usage>0</max_server_memory_usage>
              <max_thread_pool_size>10000</max_thread_pool_size>
              <max_server_memory_usage_to_ram_ratio>0.9</max_server_memory_usage_to_ram_ratio>
              <total_memory_profiler_step>4194304</total_memory_profiler_step>
              <total_memory_tracker_sample_probability>0</total_memory_tracker_sample_probability>
              <uncompressed_cache_size>8589934592</uncompressed_cache_size>
              <mark_cache_size>5368709120</mark_cache_size>
              <path>/var/lib/clickhouse/</path>
              <storage_configuration>
                  <disks>
                      <s3_cold_disk>
                          <type>s3</type>
                          <endpoint>http://blob-storage:9000/dittofeed/cold/user_events/</endpoint>
                          <access_key_id>admin</access_key_id>
                          <secret_access_key>password</secret_access_key>
                          <metadata_path>/var/lib/clickhouse/disks/s3_cold_metadata/</metadata_path>
                          <cache_enabled>false</cache_enabled>
                      </s3_cold_disk>
                  </disks>
                  <policies>
                      <cold_storage>
                          <volumes>
                              <main>
                                  <disk>s3_cold_disk</disk>
                              </main>
                          </volumes>
                      </cold_storage>
                  </policies>
              </storage_configuration>
              <tmp_path>/var/lib/clickhouse/tmp/</tmp_path>
              <user_files_path>/var/lib/clickhouse/user_files/</user_files_path>
              <ldap_servers>
              </ldap_servers>
              <user_directories>
                  <users_xml>
                      <path>users.xml</path>
                  </users_xml>
                  <local_directory>
                      <path>/var/lib/clickhouse/access/</path>
                  </local_directory>
              </user_directories>
              <default_profile>default</default_profile>
              <custom_settings_prefixes></custom_settings_prefixes>
              <default_database>default</default_database>
              <mlock_executable>true</mlock_executable>
              <remap_executable>false</remap_executable>
              <remote_servers>
                  <test_shard_localhost>
                      <shard>
                          <replica>
                              <host>localhost</host>
                              <port>9000</port>
                          </replica>
                      </shard>
                  </test_shard_localhost>
                  <test_cluster_two_shards_localhost>
                       <shard>
                           <replica>
                               <host>localhost</host>
                               <port>9000</port>
                           </replica>
                       </shard>
                       <shard>
                           <replica>
                               <host>localhost</host>
                               <port>9000</port>
                           </replica>
                       </shard>
                  </test_cluster_two_shards_localhost>
                  <test_cluster_two_shards>
                      <shard>
                          <replica>
                              <host>127.0.0.1</host>
                              <port>9000</port>
                          </replica>
                      </shard>
                      <shard>
                          <replica>
                              <host>127.0.0.2</host>
                              <port>9000</port>
                          </replica>
                      </shard>
                  </test_cluster_two_shards>
                  <test_cluster_two_shards_internal_replication>
                      <shard>
                          <internal_replication>true</internal_replication>
                          <replica>
                              <host>127.0.0.1</host>
                              <port>9000</port>
                          </replica>
                      </shard>
                      <shard>
                          <internal_replication>true</internal_replication>
                          <replica>
                              <host>127.0.0.2</host>
                              <port>9000</port>
                          </replica>
                      </shard>
                  </test_cluster_two_shards_internal_replication>
                  <test_shard_localhost_secure>
                      <shard>
                          <replica>
                              <host>localhost</host>
                              <port>9440</port>
                              <secure>1</secure>
                          </replica>
                      </shard>
                  </test_shard_localhost_secure>
                  <test_unavailable_shard>
                      <shard>
                          <replica>
                              <host>localhost</host>
                              <port>9000</port>
                          </replica>
                      </shard>
                      <shard>
                          <replica>
                              <host>localhost</host>
                              <port>1</port>
                          </replica>
                      </shard>
                  </test_unavailable_shard>
              </remote_servers>
              <remote_url_allow_hosts>
                  <host_regexp>^(blob-storage|localhost)(:\d+)?$</host_regexp>
              </remote_url_allow_hosts>
              <builtin_dictionaries_reload_interval>3600</builtin_dictionaries_reload_interval>
              <max_session_timeout>3600</max_session_timeout>
              <default_session_timeout>60</default_session_timeout>
              <query_log>
                  <database>system</database>
                  <table>query_log</table>
                  <partition_by>toYYYYMM(event_date)</partition_by>
                  <flush_interval_milliseconds>7500</flush_interval_milliseconds>
              </query_log>
              <trace_log>
                  <database>system</database>
                  <table>trace_log</table>
                  <partition_by>toYYYYMM(event_date)</partition_by>
                  <flush_interval_milliseconds>7500</flush_interval_milliseconds>
              </trace_log>
              <query_thread_log>
                  <database>system</database>
                  <table>query_thread_log</table>
                  <partition_by>toYYYYMM(event_date)</partition_by>
                  <flush_interval_milliseconds>7500</flush_interval_milliseconds>
              </query_thread_log>
              <metric_log>
                  <database>system</database>
                  <table>metric_log</table>
                  <flush_interval_milliseconds>7500</flush_interval_milliseconds>
                  <collect_interval_milliseconds>1000</collect_interval_milliseconds>
              </metric_log>
              <asynchronous_metric_log>
                  <database>system</database>
                  <table>asynchronous_metric_log</table>
                  <flush_interval_milliseconds>60000</flush_interval_milliseconds>
              </asynchronous_metric_log>
              <opentelemetry_span_log>
                  <engine>
                      engine MergeTree
                      partition by toYYYYMM(finish_date)
                      order by (finish_date, finish_time_us, trace_id)
                  </engine>
                  <database>system</database>
                  <table>opentelemetry_span_log</table>
                  <flush_interval_milliseconds>7500</flush_interval_milliseconds>
              </opentelemetry_span_log>
              <crash_log>
                  <database>system</database>
                  <table>crash_log</table>
                  <partition_by />
                  <flush_interval_milliseconds>1000</flush_interval_milliseconds>
              </crash_log>
              <top_level_domains_lists>
              </top_level_domains_lists>
              <dictionaries_config>*_dictionary.xml</dictionaries_config>
              <distributed_ddl>
                  <path>/clickhouse/task_queue/ddl</path>
              </distributed_ddl>
              <graphite_rollup_example>
                  <pattern>
                      <regexp>click_cost</regexp>
                      <function>any</function>
                      <retention>
                          <age>0</age>
                          <precision>3600</precision>
                      </retention>
                      <retention>
                          <age>86400</age>
                          <precision>60</precision>
                      </retention>
                  </pattern>
                  <default>
                      <function>max</function>
                      <retention>
                          <age>0</age>
                          <precision>60</precision>
                      </retention>
                      <retention>
                          <age>3600</age>
                          <precision>300</precision>
                      </retention>
                      <retention>
                          <age>86400</age>
                          <precision>3600</precision>
                      </retention>
                  </default>
              </graphite_rollup_example>
              <format_schema_path>/var/lib/clickhouse/format_schemas/</format_schema_path>
              <query_masking_rules>
                  <rule>
                      <name>hide encrypt/decrypt arguments</name>
                      <regexp>((?:aes_)?(?:encrypt|decrypt)(?:_mysql)?)\s*\(\s*(?:'(?:\\'|.)+'|.*?)\s*\)</regexp>
                      <replace>\1(???)</replace>
                  </rule>
              </query_masking_rules>
              <send_crash_reports>
                  <enabled>false</enabled>
                  <anonymize>false</anonymize>
                  <endpoint>https://6f33034cfe684dd7a3ab9875e57b1c8d@o388870.ingest.sentry.io/5226277</endpoint>
              </send_crash_reports>
              <kafka>
                  <security_protocol>sasl_plaintext</security_protocol>
                  <sasl_mechanism>PLAIN</sasl_mechanism>
                  <sasl_username>admin</sasl_username>
                  <sasl_password>password</sasl_password>
              </kafka>
          </yandex>
      
    networks:
      - dittofeed-network
  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    profiles: ["otel"]
    command: ["--config", "/etc/otel-collector-config.yaml"]
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - 1888:1888 # pprof extension
      - 8888:8888 # Prometheus metrics exposed by the collector
      - 8889:8889 # Prometheus exporter metrics
      - 13133:13133 # health_check extension
      - 4317:4317 # OTLP gRPC receiver
      - 4318:4318 # OTLP http receiver
      - 55679:55679 # zpages extension
    networks:
      - dittofeed-network
  zipkin:
    image: openzipkin/zipkin
    profiles: ["otel"]
    container_name: zipkin
    ports:
      - 9411:9411
    networks:
      - dittofeed-network
  grafana:
    image: grafana/grafana
    profiles: ["otel"]
    ports:
      - "9091:3000"
    volumes:
      - ./grafana-datasource-prometheus.yaml:/etc/grafana/provisioning/datasources/grafana-datasource-prometheus.yaml
      - grafana-storage:/var/lib/grafana
    networks:
      - dittofeed-network
  prometheus:
    image: prom/prometheus
    profiles: ["otel"]
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yaml:/etc/prometheus/prometheus.yml
      - prometheus-storage:/prometheus
    networks:
      - dittofeed-network
  mail-server:
    profiles: ["smtp"]
    image: mailhog/mailhog
    ports:
      - "1025:1025" # SMTP server
      - "8025:8025" # Web interface
    networks:
      - dittofeed-network
  # Note that minio is only used for local development. In production, use any S3-compatible storage.
  blob-storage:
    image: minio/minio
    ports:
      - "9010:9000"
      - "9011:9001"
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: password
    volumes:
      - blob-storage:/data
    command: server --console-address ":9001" /data
    networks:
      - dittofeed-network

volumes:
  postgres:
  kafka:
  clickhouse_lib:
  clickhouse_log:
  grafana-storage:
  prometheus-storage:
  blob-storage:

networks:
  dittofeed-network:
    driver: bridge
    name: dittofeed-network
